<div align="center">
<h1>CIFAR-10 Classifier
</h1>



[Xiucheng Wang](https://wxiucheng.github.io/)&#8224; 

[Beihang University]


<a href="https://wxiucheng.github.io/">
<img src='https://img.shields.io/badge/arxiv-Cifar10Classifier-blue' alt='Paper PDF'></a>
<a href="https://wxiucheng.github.io/cifar10-classifier/">
<img src='https://img.shields.io/badge/Project-Website-orange' alt='Project Page'></a>
</div>

## ğŸ“– Abstract
- ç®€å• CNN ä¸ ResNet18 ä¸¤å¥—æ¨¡å‹ï¼Œæ”¯æŒé¢„è®­ç»ƒå¾®è°ƒ
- ç»Ÿä¸€çš„ YAML é…ç½®é©±åŠ¨ï¼ˆæ¨¡å‹/æ•°æ®/è®­ç»ƒï¼‰
- è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•å…¨æµç¨‹ä¸æœ€ä¼˜/æœ€åæƒé‡ä¿å­˜
- è¯„ä¼°è„šæœ¬ä¸ Gradio å¯è§†åŒ– Demo

![DreamText Teaser](demo/teaser.png)

## ğŸ”§ Usage

### Environment Setup

```bash
conda create -n dreamtext python=3.11
conda activate dreamtext
pip install -r requirements.txt
```

### Download our Pre-trained Models
Download our available [checkpoints](https://drive.google.com/file/d/1Q4B0oAnksORsPJS5TwoJU5uPRSFEbwS5/view?usp=sharing) and put them in the corresponding directories in `./checkpoints`.


## ğŸš€ Gradio Demo
You can run the demo locally by
```
python run_gradio.py
```
<img src=demo/gradio.png style="zoom:30%" />


## ğŸ¨ Preparing Datasets


### LAION-OCR
- Create a data directory `{your data root}/LAION-OCR` in your disk and put your data in it. Then set the **data_root** field in `./configs/dataset/locr.yaml`.
- For the downloading and preprocessing of Laion-OCR dataset, please refer to [TextDiffuser](https://github.com/microsoft/unilm/tree/master/textdiffuser) and `./scripts/preprocess/laion_ocr_pre.ipynb`.

### ICDAR13
- Create a data directory `{your data root}/ICDAR13` in your disk and put your data in it. Then set the **data_root** field in `./configs/dataset/icd13.yaml`.
- Build the tree structure as below:
```
ICDAR13
â”œâ”€â”€ train                  // training set
    â”œâ”€â”€ annos              // annotations
        â”œâ”€â”€ gt_x.txt
        â”œâ”€â”€ ...
    â””â”€â”€ images             // images
        â”œâ”€â”€ img_x.jpg
        â”œâ”€â”€ ...
â””â”€â”€ val                    // validation set
    â”œâ”€â”€ annos              // annotations
        â”œâ”€â”€ gt_img_x.txt
        â”œâ”€â”€ ...
    â””â”€â”€ images             // images
        â”œâ”€â”€ img_x.jpg
        â”œâ”€â”€ ...
```

### TextSeg
- Create a data directory `{your data root}/TextSeg` in your disk and put your data in it. Then set the **data_root** field in `./configs/dataset/tsg.yaml`.
- Build the tree structure as below:
```
TextSeg
â”œâ”€â”€ train                  // training set
    â”œâ”€â”€ annotation         // annotations
        â”œâ”€â”€ x_anno.json    // annotation json file
        â”œâ”€â”€ x_mask.png     // character-level mask
        â”œâ”€â”€ ...
    â””â”€â”€ image              // images
        â”œâ”€â”€ x.jpg.jpg
        â”œâ”€â”€ ...
â””â”€â”€ val                    // validation set
    â”œâ”€â”€ annotation         // annotations
        â”œâ”€â”€ x_anno.json    // annotation json file
        â”œâ”€â”€ x_mask.png     // character-level mask
        â”œâ”€â”€ ...
    â””â”€â”€ image              // images
        â”œâ”€â”€ x.jpg
        â”œâ”€â”€ ...
```

### SynthText
- Create a data directory `{your data root}/SynthText` in your disk and put your data in it. Then set the **data_root** field in `./configs/dataset/st.yaml`.
- Build the tree structure as below:
```
SynthText
â”œâ”€â”€ 1                      // part 1
    â”œâ”€â”€ ant+hill_1_0.jpg   // image
    â”œâ”€â”€ ant+hill_1_1.jpg
    â”œâ”€â”€ ...
â”œâ”€â”€ 2                      // part 2
â”œâ”€â”€ ...
â””â”€â”€ gt.mat                 // annotation file
```



## ğŸ’» Training
Download the [stable-diffusion-2-inpainting](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting/blob/main/512-inpainting-ema.ckpt) and put it in `./checkpoints/pretrained/`.

Set the parameters in `./configs/train.yaml` and run:

```
python train.py
```

## âœ¨ Evaluation
Set the parameters in `./configs/test.yaml` and run:

```
python test.py
```



## ğŸ« License
For non-commercial academic use, this project is licensed under [the 2-clause BSD License](https://opensource.org/license/bsd-2-clause). 
For commercial use, please contact [Cheng Jin](jc@fudan.edu.cn).


## â­ BibTeX
If you find our work helpful, please leave us a star and cite our paper.

```bibtex
@inproceedings{DreamText,
      title={High Fidelity Scene Text Synthesis},
      author={Wang, Yibin and Zhang, Weizhong and Honghui, Xu and Jin, Cheng},
      booktitle={CVPR},
      year={2025}
    }
```


## ğŸ“§ Contact

If you have any technical comments or questions, please open a new issue or feel free to contact [Yibin Wang](https://codegoat24.github.io).


## ğŸ™ Acknowledgements

Our work is based on [Stable-Diffusion](https://github.com/Stability-AI/stablediffusion), thanks to all the contributors!
